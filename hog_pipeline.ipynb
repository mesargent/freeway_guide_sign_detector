{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils\n",
    "from skimage import data, color, exposure\n",
    "from sklearn import svm\n",
    "import cPickle as pickle\n",
    "import data_generator as dg\n",
    "import multiscale_detect as md\n",
    "import kmeansutil as ku\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data array from generate_data module. Randomize the array. Pick sample_size amount from each\n",
    "\n",
    "Data is stored in a pickled zipped list of features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46285263035703317, 0.77338458477358618, 1.1003667227651768]\n"
     ]
    }
   ],
   "source": [
    "#get positive images, determine best ratios, assign to images\n",
    "\n",
    "pimages = dg.getImagesFromJSON(open(\"labels.json\").read())\n",
    "clusters, images = ku.addClusterLabels(pimages)\n",
    "ratios = [r[0] for r in clusters]\n",
    "ratios.sort()\n",
    "print ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate positive images into aspect ratios, get negative images and crop to aspect ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number pos imgs at ratio 0:  53\n",
      "Number pos imgs at ratio 1:  140\n",
      "Number pos imgs at ratio 2:  77\n",
      "Number neg imgs at ratio 0:  1000\n",
      "Number neg imgs at ratio 1:  1000\n",
      "Number pos neg at ratio 2:  1000\n"
     ]
    }
   ],
   "source": [
    "pratio0imgs = []\n",
    "pratio1imgs = []\n",
    "pratio2imgs = []\n",
    "\n",
    "for image in images:\n",
    "    if image[1] == 0:\n",
    "        pratio0imgs.append(image[0])\n",
    "    elif image[1] == 1:\n",
    "        pratio1imgs.append(image[0])\n",
    "    elif image[1] == 2:\n",
    "        pratio2imgs.append(image[0])\n",
    "\n",
    "print \"Number pos imgs at ratio 0: \", len(pratio0imgs)\n",
    "print \"Number pos imgs at ratio 1: \", len(pratio1imgs)\n",
    "print \"Number pos imgs at ratio 2: \", len(pratio2imgs)\n",
    "        \n",
    "#get negative images, use ratios found for positive images to match\n",
    "nimgfiles = dg.getAllFiles(\"blanks\")\n",
    "nimages = [cv2.imread(\"blanks/\"+ f) for f in nimgfiles]\n",
    "   \n",
    "nratio0imgs = [dg.cropToRatio(x, ratios[0]) for x in nimages]\n",
    "nratio1imgs = [dg.cropToRatio(x, ratios[1]) for x in nimages]\n",
    "nratio2imgs = [dg.cropToRatio(x, ratios[2]) for x in nimages]\n",
    "\n",
    "print \"Number neg imgs at ratio 0: \", len(nratio0imgs)\n",
    "print \"Number neg imgs at ratio 1: \", len(nratio1imgs)\n",
    "print \"Number pos neg at ratio 2: \", len(nratio2imgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Generate features from HOGs and images for each label and aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getFeaturesWithLabel(imageData, hog, dims, label):\n",
    "    data = []\n",
    "    for img in imageData: \n",
    "        img = cv2.resize(img, dims)\n",
    "\n",
    "        #for images with transparency layer, reduce to 3 layers\n",
    "        feat = hog.compute(img)\n",
    "        \n",
    "        data.append((feat, label))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 32)\n"
     ]
    }
   ],
   "source": [
    "minDim = 80\n",
    "HOGs, dims = dg.ratiosToHOGS(ratios, minDim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdata0ratio = getFeaturesWithLabel(pratio0imgs, HOGs[0], dims[0], 1)\n",
    "pdata1ratio = getFeaturesWithLabel(pratio1imgs, HOGs[1], dims[1], 1)\n",
    "pdata2ratio = getFeaturesWithLabel(pratio2imgs, HOGs[2], dims[2], 1)\n",
    "\n",
    "ndata0ratio = getFeaturesWithLabel(nratio0imgs, HOGs[0], dims[0], 0)\n",
    "ndata1ratio = getFeaturesWithLabel(nratio1imgs, HOGs[1], dims[1], 0)\n",
    "ndata2ratio = getFeaturesWithLabel(nratio2imgs, HOGs[2], dims[2], 0)\n",
    "\n",
    "data0ratio = pdata0ratio + ndata0ratio\n",
    "data1ratio = pdata1ratio + ndata1ratio\n",
    "data2ratio = pdata2ratio + ndata2ratio\n",
    "\n",
    "shuffle(data0ratio)\n",
    "shuffle(data1ratio)\n",
    "shuffle(data2ratio)\n",
    "\n",
    "feat0, label0 = map(list, zip(*data0ratio))\n",
    "feat1, label1 = map(list, zip(*data1ratio))\n",
    "feat2, label2 = map(list, zip(*data2ratio))\n",
    "\n",
    "feat0 = [x.flatten() for x in feat0]\n",
    "feat1 = [x.flatten() for x in feat1]\n",
    "feat2 = [x.flatten() for x in feat2]\n",
    "\n",
    "sample_size0 = len(feat0)\n",
    "sample_size1 = len(feat1)\n",
    "sample_size2 = len(feat2)\n",
    "\n",
    "train_size0 = int(round(.8*sample_size0))\n",
    "train_size1 = int(round(.8*sample_size1))\n",
    "train_size2 = int(round(.8*sample_size2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_feat0 = np.array(feat0[:train_size0], np.float32)\n",
    "test_feat0= np.array(feat0[train_size0: sample_size0], np.float32)\n",
    "train_label0 = np.array(label0[:train_size0])\n",
    "test_label0 = np.array(label0[train_size0:sample_size0])\n",
    "\n",
    "train_feat1= np.array(feat1[:train_size1], np.float32)\n",
    "test_feat1 = np.array(feat1[train_size1: sample_size1], np.float32)\n",
    "train_label1 = np.array(label1[:train_size1])\n",
    "test_label1 = np.array(label1[train_size1:sample_size1])\n",
    "\n",
    "train_feat2 = np.array(feat2[:train_size2], np.float32)\n",
    "test_feat2 = np.array(feat2[train_size2: sample_size2], np.float32)\n",
    "train_label2 = np.array(label2[:train_size2])\n",
    "test_label2 = np.array(label2[train_size2:sample_size2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=5, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvm0 = svm.SVC(gamma=5, C=.1, kernel=\"linear\")\n",
    "lsvm0.fit(train_feat0, train_label0)\n",
    "\n",
    "lsvm1 = svm.SVC(gamma=5, C=.1, kernel=\"linear\")\n",
    "lsvm1.fit(train_feat1, train_label1)\n",
    "\n",
    "lsvm2 = svm.SVC(gamma=5, C=.1, kernel=\"linear\")\n",
    "lsvm2.fit(train_feat2, train_label2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute and display training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998812351544\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print lsvm0.score(train_feat0, train_label0)\n",
    "print lsvm1.score(train_feat1, train_label1)\n",
    "print lsvm2.score(train_feat2, train_label2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute and display test set accuracy, true and false positives, true and false negatives, list of files that were misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy aspect ratio 0 0.995260663507\n",
      "test accuracy aspect ratio 1 0.986842105263\n",
      "test accuracy aspect ratio 2 0.986046511628\n",
      "first aspect ratio:\n",
      "true positives: 12 true_negatives: 198 false positives: 0 false_negatives: 1 \n",
      "\n",
      "second aspect ratio:\n",
      "true positives: 31 true_negatives: 194 false positives: 1 false_negatives: 2 \n",
      "\n",
      "third aspect ratio:\n",
      "true positives: 16 true_negatives: 196 false positives: 0 false_negatives: 3 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def printConfusionMatrix(result, labels):\n",
    "    result0 = [int(x) for x in result]\n",
    "\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    true_positives = 0\n",
    "    true_negatives = 0\n",
    "\n",
    "    for i, row in enumerate(labels):\n",
    "        if row  == 1 and result[i] == 1: \n",
    "            true_positives +=1\n",
    "        if row  != 1 and result[i] != 1: \n",
    "            true_negatives +=1\n",
    "        if row  != 1 and result[i] == 1: \n",
    "            false_positives +=1\n",
    "        if row == 1 and result[i] != 1: \n",
    "            false_negatives +=1\t\n",
    "\n",
    "    print \"true positives:\", true_positives, \"true_negatives:\", true_negatives, \"false positives:\", false_positives, \"false_negatives:\", false_negatives, \"\\n\"\n",
    "\n",
    "\n",
    "#compute test accuracy\n",
    "result0 = lsvm0.predict(test_feat0)\n",
    "result1 = lsvm1.predict(test_feat1)\n",
    "result2 = lsvm2.predict(test_feat2)\n",
    "\n",
    "print \"test accuracy aspect ratio 0\", lsvm0.score(test_feat0, test_label0)\n",
    "print \"test accuracy aspect ratio 1\", lsvm1.score(test_feat1, test_label1)\n",
    "print \"test accuracy aspect ratio 2\", lsvm2.score(test_feat2, test_label2)\n",
    "\n",
    "print \"first aspect ratio:\"\n",
    "printConfusionMatrix(result0, test_label0)\n",
    "\n",
    "print \"second aspect ratio:\"\n",
    "printConfusionMatrix(result1, test_label1)\n",
    "\n",
    "print \"third aspect ratio:\"\n",
    "printConfusionMatrix(result2, test_label2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard Negative Mining: scan negative images for false positives, store windows for retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get dataset of negative images to scan through\n",
    "neg_files = gs.getAllFiles(\"hwy_empty\")\n",
    "neg_imgs = []\n",
    "false_pos_feat = []\n",
    "signs = 0\n",
    "nosigns = 0\n",
    "\n",
    "for f in neg_files:\n",
    "    neg_imgs.append([f, cv2.imread(\"hwy_empty/\" + f)])\n",
    "\n",
    "#checking contents\n",
    "print len(neg_imgs)\n",
    "\n",
    "#multiscale detect\n",
    "\n",
    "import multiscale_detect as md\n",
    "counter = 1\n",
    "for row in neg_imgs:\n",
    "    scales = md.pyramid(row[1], scale=1.5, minSize=(30, 30))\n",
    "    winh = 80\n",
    "    winw = 80\n",
    "     \n",
    "    for img in scales:\n",
    "        results = []\n",
    " \n",
    "        for (x, y, window) in md.sliding_window(img, 40, (winw, winh)):        \n",
    "            if window.shape[0] != winh or window.shape[1] != winw:\n",
    "                continue\n",
    "            window = cv2.resize(window, (80, 80))\n",
    "            feat = hog.compute(window)\n",
    "            result = lsvm.predict(feat.reshape(1,-1))[0]\n",
    "            if result == 1:  \n",
    "                false_pos_feat.append(feat)\n",
    "                signs +=1\n",
    "            else:\n",
    "                nosigns+=1\n",
    "    counter +=1\n",
    "\n",
    "\n",
    "print \"signs\", signs, \"no signs\", nosigns\n",
    "false_pos_feat = [x.flatten() for x in false_pos_feat] \n",
    "print len(false_pos_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "false_pos_labels = [0] * len(false_pos_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#retrain classifier with false positives from hard negative mining\n",
    "train_features_wfp = np.r_[train_features, np.array(false_pos_feat)]\n",
    "train_labels_wfp = np.r_[train_labels, np.array(false_pos_labels)]\n",
    "print train_features_wfp.shape, train_labels_wfp.shape\n",
    "\n",
    "lsvm.fit(train_features_wfp, train_labels_wfp)\n",
    "print \"training accuracy\", lsvm.score(train_features_wfp, train_labels_wfp)\n",
    "#compute test accuracy\n",
    "result = lsvm.predict(test_features)\n",
    "print \"test accuracy\", lsvm.score(test_features, test_labels)\n",
    "result = [int(x) for x in result]\n",
    "\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "true_positives = 0\n",
    "true_negatives = 0\n",
    "\n",
    "false_pos_filenames = []\n",
    "false_neg_filenames = []\n",
    "true_pos_filenames = []\n",
    "for i, row in enumerate(test_labels):\n",
    "    if row  == 1 and result[i] == 1: \n",
    "        true_positives +=1\n",
    "    if row  != 1 and result[i] != 1: \n",
    "        true_negatives +=1\n",
    "    if row  != 1 and result[i] == 1: \n",
    "        false_positives +=1\n",
    "    if row == 1 and result[i] != 1: \n",
    "        false_negatives +=1\t\n",
    "\n",
    "print \"true positives:\", true_positives, \"true_negatives:\", true_negatives, \"false positives:\", false_positives, \"false_negatives:\", false_negatives, \"\\n\"\n",
    "# print \"false positives\", false_pos_filenames, \"\\n\"\n",
    "# print \"false negatives\", false_neg_filenames, \"\\n\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find and display signs in a test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def transform_scale(factor, boxes):\n",
    "    return [(int(x1*factor), int(y1*factor), int(x2*factor), int(y2*factor)) for (x1,y1,x2,y2) in boxes]\n",
    "\n",
    "\n",
    "import multiscale_detect as md\n",
    "from random import randint\n",
    "color = (0,255,0)\n",
    "clone = None\n",
    "dir = \"multiscale_test\"\n",
    "files = os.listdir(dir)\n",
    "for i in range(len(files)):\n",
    "    test_image = cv2.imread(dir+\"/\"+files[i])\n",
    "    if test_image != None and test_image.any():\n",
    "        test_image = imutils.resize(test_image, width=min(600, test_image.shape[1]))\n",
    "        clone = test_image.copy()\n",
    "        clone = cv2.cvtColor(clone, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        pscale = 1.1\n",
    "        scales = md.pyramid(test_image, scale=pscale, minSize=(20, 20))\n",
    "        winh = 54\n",
    "        winw = 80\n",
    "        scaled_results = []\n",
    "\n",
    "        for i, img in enumerate(scales):\n",
    "            results = []\n",
    "\n",
    "            for (x, y, window) in md.sliding_window(img, 20, (winw, winh)):        \n",
    "                if window.shape[0] != winh or window.shape[1] != winw:\n",
    "                    continue\n",
    "                wclone = img.copy()\n",
    "                wclone = cv2.cvtColor(wclone, cv2.COLOR_BGR2RGB)\n",
    "                window = cv2.resize(window, (80, 80))\n",
    "                feat = hog.compute(window)\n",
    "                result = lsvm.predict(feat.reshape(1,-1))[0]\n",
    "                if result == 1:\n",
    "                    results.append((x, y, x+winw, y+winh))\n",
    "\n",
    "            factor = float(clone.shape[0])/img.shape[0]   \n",
    "            scaled = transform_scale(factor, results)\n",
    "            scaled_results.extend(scaled)\n",
    "\n",
    "\n",
    "        scaled_results = md.non_max_suppression_fast(np.array(scaled_results), .3)\n",
    "        for x1, y1, x2, y2 in scaled_results:\n",
    "            cv2.rectangle(clone, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "        plt.imshow(clone)\n",
    "        plt.show()\n",
    "    else: print \"Image not found\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
